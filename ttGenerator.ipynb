{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ttGenerator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAbmZR-Fuw3g",
        "outputId": "a0a44d10-426f-456d-e20d-95b54775b93d"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import timeit\n",
        "\n",
        "# load and lightly pre-process data\n",
        "text = open(\"dataset.txt\", 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "print(text[:100])\n",
        "\n",
        "# calculate the vocabulary (number of unique characters in text)\n",
        "vocab = sorted(set(text))\n",
        "print('{} unique characters'.format(len(vocab)))\n",
        "\n",
        "# mapping from unique characters to indices\n",
        "char_to_index = {u: i for i, u in enumerate(vocab)}\n",
        "index_to_char = np.array(vocab)\n",
        "\n",
        "# numerical representation of text\n",
        "text_as_int = np.array([char_to_index[c] for c in text])\n",
        "\n",
        "# define the sequence length, which will determine how many example pairs per epoch\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "\n",
        "def split_input_target(chunk):\n",
        "    \"\"\"Split a chunk of length n+1 into a tuple containing the the input (first n chars)\n",
        "        and the target (last n chars) \"\"\"\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "\n",
        "    print('input', input_text)\n",
        "    print('target', target_text)\n",
        "\n",
        "    return input_text, target_text\n",
        "\n",
        "\n",
        "# create the dataset\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "dataset = sequences.map(split_input_target)\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 64\n",
        "rnn_units = 256\n",
        "\n",
        "\n",
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    \"\"\"Define the model: character embedding -> GRU -> fully connected \"\"\"\n",
        "    with tf.device('/device:GPU:0'):\n",
        "        model = tf.keras.Sequential([\n",
        "            tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                      batch_input_shape=[batch_size, None]),\n",
        "            tf.keras.layers.GRU(rnn_units,\n",
        "                                return_sequences=True,\n",
        "                                stateful=True,\n",
        "                                recurrent_initializer='glorot_uniform'),\n",
        "            tf.keras.layers.Dense(vocab_size)\n",
        "        ])\n",
        "        return model\n",
        "\n",
        "train = False\n",
        "if train:\n",
        "    with tf.device('/device:GPU:0'):\n",
        "        model = build_model(vocab_size, embedding_dim, rnn_units, BATCH_SIZE)\n",
        "        model.summary()\n",
        "\n",
        "        def loss(labels, logits):\n",
        "            return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "        # attach optimizer and loss\n",
        "        model.compile(optimizer='adam', loss=loss)\n",
        "\n",
        "        # Set up directory for saving checkpoints of the model\n",
        "        checkpoint_dir = './training_checkpoints'\n",
        "        checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "        checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "            filepath=checkpoint_prefix,\n",
        "            save_weights_only=True)\n",
        "\n",
        "        EPOCHS = 30\n",
        "        history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])\n",
        "\n",
        "\n",
        "def generate_text(model, start_string):\n",
        "    \"\"\"Generate text, given a trained model and a starting string\"\"\"\n",
        "    num_generate = 500\n",
        "    input_eval = [char_to_index[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "    text_generated = []\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "        text_generated.append(index_to_char[predicted_id])\n",
        "\n",
        "    return start_string + ''.join(text_generated)\n",
        "\n",
        "\n",
        "# set generate to True to generate text\n",
        "generate = True\n",
        "if generate:\n",
        "    # load the model back from a checkpoint\n",
        "    checkpoint_dir = './training_checkpoints'\n",
        "    model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "    model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "    model.build(tf.TensorShape([1, None]))\n",
        "    print(generate_text(model, start_string=\"Hillary\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Be sure to tune in and watch Donald Trump on Late Night with David Letterman as he presents the Top \n",
            "259 unique characters\n",
            "input Tensor(\"strided_slice:0\", shape=(100,), dtype=int64)\n",
            "target Tensor(\"strided_slice_1:0\", shape=(100,), dtype=int64)\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "Hillary Championships, and Douging less fed cars – they declarred. Wis the students, phone can teams for U signed out of the mas indulling more costly big problems are afreased with the ring up, all of the cohere so Comey. The Pakio Dismavins, with hit on Stote (Hech)!\n",
            "The Authort, we want Street JA Trump was open. Big ramifraud Don & Start free!  pic.twitter.com/EJGdvX2vbrr\n",
            "1211 show @ FoxNews “Make America Great Arbissid, and Saturday Nowhert survivers & congrats wed to Adam McCain, Jep, more than Am\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}